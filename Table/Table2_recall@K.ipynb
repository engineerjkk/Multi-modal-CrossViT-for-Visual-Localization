{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm, tqdm.notebook\n",
    "tqdm.tqdm = tqdm.notebook.tqdm\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hloc.utils.read_write_model import read_images_binary\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Base path configuration (상대 경로)\n",
    "BASE_PATH = '..'\n",
    "\n",
    "# Derived paths\n",
    "PATHS = {\n",
    "    'database': os.path.join(BASE_PATH, 'DataBase'),\n",
    "    'global_desc': os.path.join(BASE_PATH, 'GlobalDescriptors'),\n",
    "    'outputs': os.path.join(BASE_PATH, 'outputs')\n",
    "}\n",
    "\n",
    "# Constants\n",
    "K_VALUES = [200, 150, 100, 50, 20, 5, 1]\n",
    "MODEL_NAMES = ['1st', '2nd', '3rd', '4th', '5th']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"데이터베이스와 이미지 데이터 로드\"\"\"\n",
    "    database_path = os.path.join(PATHS['database'], 'DataBase_Norm_Tiny.pickle')\n",
    "    images_path = os.path.join(PATHS['outputs'], 'aachen/sfm_superpoint+superglue/images.bin')\n",
    "    \n",
    "    with open(database_path, 'rb') as f:\n",
    "        database = pickle.load(f)\n",
    "    \n",
    "    images = read_images_binary(images_path)\n",
    "    return database, images\n",
    "\n",
    "def calculate_recall(reference_file, anc_pos_relations, images):\n",
    "    \"\"\"Recall 계산\"\"\"\n",
    "    search_results = {}\n",
    "    total_image_id = list(images.keys())\n",
    "    \n",
    "    # Parse reference file\n",
    "    with open(reference_file, 'r') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                anchor_img, result_img = line.strip().split()\n",
    "                anchor_key = None\n",
    "                result_key = None\n",
    "                \n",
    "                for j in total_image_id:\n",
    "                    tar_img = images[j]\n",
    "                    if tar_img.name == anchor_img:\n",
    "                        anchor_key = j\n",
    "                    if tar_img.name == result_img:\n",
    "                        result_key = j\n",
    "                        \n",
    "                if anchor_key not in search_results:\n",
    "                    search_results[anchor_key] = []\n",
    "                search_results[anchor_key].append(result_key)\n",
    "            except ValueError as e:\n",
    "                print(f\"Error processing line in {reference_file}: {line.strip()}\")\n",
    "                continue\n",
    "    \n",
    "    # Calculate recall\n",
    "    recalls = []\n",
    "    for anchor_key, results in search_results.items():\n",
    "        found_positive = 0\n",
    "        for item in anc_pos_relations:\n",
    "            if item['Anchor'][0] == anchor_key:\n",
    "                anchor_positives = item['Positive']\n",
    "                for result_key in results:\n",
    "                    if result_key in anchor_positives:\n",
    "                        found_positive = 1\n",
    "                        break\n",
    "                break\n",
    "        recalls.append(found_positive)\n",
    "    \n",
    "    return np.mean(recalls) if recalls else 0.0\n",
    "\n",
    "def process_all():\n",
    "    \"\"\"모든 모델에 대해 처리\"\"\"\n",
    "    database, images = load_data()\n",
    "    results = {k: [] for k in K_VALUES}\n",
    "    \n",
    "    for model_name in tqdm(MODEL_NAMES):\n",
    "        print(f\"\\nProcessing {model_name} model...\")\n",
    "        \n",
    "        for k in K_VALUES:\n",
    "            reference_file = os.path.join(PATHS['global_desc'], f'{model_name}_StudentReference_{k}.txt')\n",
    "            \n",
    "            try:\n",
    "                recall = calculate_recall(reference_file, database, images)\n",
    "                results[k].append(recall)\n",
    "                print(f\"k={k}: {recall:.4f}\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found for {model_name} model, k={k}\")\n",
    "                results[k].append(None)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def display_results(results):\n",
    "    \"\"\"결과 출력\"\"\"\n",
    "    print(\"\\n=== Average Recall Values ===\")\n",
    "    print(\"\\nk values:\", end=\"\")\n",
    "    for k in K_VALUES:\n",
    "        print(f\"\\t{k}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    # Print individual model results\n",
    "    for i, model_name in enumerate(MODEL_NAMES):\n",
    "        print(f\"\\n{model_name} model:\", end=\"\")\n",
    "        for k in K_VALUES:\n",
    "            if results[k][i] is not None:\n",
    "                print(f\"\\t{results[k][i]:.4f}\", end=\"\")\n",
    "            else:\n",
    "                print(\"\\tN/A\", end=\"\")\n",
    "    \n",
    "    # Calculate and print averages\n",
    "    print(\"\\n\\nAverage:\", end=\"\")\n",
    "    for k in K_VALUES:\n",
    "        values = [v for v in results[k] if v is not None]\n",
    "        if values:\n",
    "            avg = np.mean(values)\n",
    "            print(f\"\\t{avg:.4f}\", end=\"\")\n",
    "        else:\n",
    "            print(\"\\tN/A\", end=\"\")\n",
    "    \n",
    "    # Print summary for easy copying\n",
    "    print(\"\\n\\nprint('Average recall values for different k:')\")\n",
    "    for k in K_VALUES:\n",
    "        values = [v for v in results[k] if v is not None]\n",
    "        if values:\n",
    "            avg = np.mean(values)\n",
    "            print(f\"k = {k}: {avg:.4f}\")\n",
    "\n",
    "def save_results(results):\n",
    "    \"\"\"결과를 JSON 파일로 저장\"\"\"\n",
    "    print(\"\\nSaving results to recall_results.json\")\n",
    "    output_data = {\n",
    "        str(k): [float(v) if v is not None else None for v in vals]\n",
    "        for k, vals in results.items()\n",
    "    }\n",
    "    \n",
    "    with open('recall@K_results.json', 'w') as f:\n",
    "        json.dump(output_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f418adceb2da4105b4b4a2ee5bc0e496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 1st model...\n",
      "k=200: 0.9977\n",
      "k=150: 0.9977\n",
      "k=100: 0.9965\n",
      "k=50: 0.9908\n",
      "k=20: 0.9850\n",
      "k=5: 0.9643\n",
      "k=1: 0.9021\n",
      "\n",
      "Processing 2nd model...\n",
      "k=200: 0.9965\n",
      "k=150: 0.9965\n",
      "k=100: 0.9965\n",
      "k=50: 0.9942\n",
      "k=20: 0.9838\n",
      "k=5: 0.9653\n",
      "k=1: 0.8924\n",
      "\n",
      "Processing 3rd model...\n",
      "k=200: 0.9965\n",
      "k=150: 0.9942\n",
      "k=100: 0.9931\n",
      "k=50: 0.9919\n",
      "k=20: 0.9873\n",
      "k=5: 0.9711\n",
      "k=1: 0.9062\n",
      "\n",
      "Processing 4th model...\n",
      "k=200: 0.9919\n",
      "k=150: 0.9896\n",
      "k=100: 0.9884\n",
      "k=50: 0.9850\n",
      "k=20: 0.9745\n",
      "k=5: 0.9583\n",
      "k=1: 0.8843\n",
      "\n",
      "Processing 5th model...\n",
      "k=200: 0.9988\n",
      "k=150: 0.9977\n",
      "k=100: 0.9942\n",
      "k=50: 0.9907\n",
      "k=20: 0.9850\n",
      "k=5: 0.9676\n",
      "k=1: 0.9016\n"
     ]
    }
   ],
   "source": [
    "results = process_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Average Recall Values ===\n",
      "\n",
      "k values:\t200\t150\t100\t50\t20\t5\t1\n",
      "\n",
      "1st model:\t0.9977\t0.9977\t0.9965\t0.9908\t0.9850\t0.9643\t0.9021\n",
      "2nd model:\t0.9965\t0.9965\t0.9965\t0.9942\t0.9838\t0.9653\t0.8924\n",
      "3rd model:\t0.9965\t0.9942\t0.9931\t0.9919\t0.9873\t0.9711\t0.9062\n",
      "4th model:\t0.9919\t0.9896\t0.9884\t0.9850\t0.9745\t0.9583\t0.8843\n",
      "5th model:\t0.9988\t0.9977\t0.9942\t0.9907\t0.9850\t0.9676\t0.9016\n",
      "\n",
      "Average:\t0.9963\t0.9951\t0.9938\t0.9905\t0.9831\t0.9653\t0.8973\n",
      "\n",
      "print('Average recall values for different k:')\n",
      "k = 200: 0.9963\n",
      "k = 150: 0.9951\n",
      "k = 100: 0.9938\n",
      "k = 50: 0.9905\n",
      "k = 20: 0.9831\n",
      "k = 5: 0.9653\n",
      "k = 1: 0.8973\n"
     ]
    }
   ],
   "source": [
    "display_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving results to recall_results.json\n"
     ]
    }
   ],
   "source": [
    "save_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JKK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
